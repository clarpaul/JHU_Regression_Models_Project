---
title: "Regression Models Course Project"
author: "Paul Clark: March 5, 2017"
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: preamble-latex.tex
    number_sections: yes
  html_notebook:
    fig_caption: yes
    number_sections: yes
---

# Executive Summary

For its 1974 edition, US magazine *Motor Trend* has asked two questions to be addressed using data on fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973-74 models). **Quesiton 1:** *“Is an automatic or manual transmission better for MPG?”* **Question 2:** *"How does MPG differ, quantitatively, between automatic and manual transmissions?"* The variables are described below:
```{r intro, echo = FALSE, comment=""}
  c( "mpg  Miles/(US) gallon", "cyl  Num cylinders", "disp Displacement (cu.in.)", 
     "hp   Gross horsepower", "drat Rear axle ratio",
     "wt   Weight (1000 lbs)", "qsec 1/4 mile time", 
     "vs   Engine(0=V,1=Inline)","am   Transmission(0=auto,1=man)",
     "gear Num forward gears", "carb Num carburetors")  
```
We address the questions via two approaches: **Approach (a)** *- Calculation of mean differenc and two-sample T-test on `mpg` of the transmission types.* **Approach (b)** *- Adjustment of the `am` effect in (a) by regressing `mpg` on all other variables in the data.* Note: for either approach to be meaningful, this small sample of 32 cars must be representative of their populations.

We conclude from **Approach (a)** that the two groups of cars come from populations with statistically different means. If the data provided is representative, then *manual* transmission cars generally have an estimtaed mean `mpg` 7.2 MPG higher than *automatic* cars.  

From **Approach (b)**, we have two main conclusions: **(1)** the adjustments of the `am` effect that best predict `mpg` are `hp` and `wt`, both negative, corresponding to model $\textbf{E[mpg] = M}\cdot am + \textbf{H}\cdot hp + \textbf{W}\cdot wt$; **(2)** the *automatic/manual* effect $M$, with *horsepower* and *weight* held fixed, is approximately 2.1 mpg, with manual again having higher `mpg` than automatic.  

# Exploratory Data Analysis
In **Figure 1**, we examine integer predictors to decide whether to treat as factors. We find value in treating `cyl` and `carb` as continuous: they show clear trends vs. other variables. From a pairs plot, **Figure 2**, we see many strong correlations, so model selection should consider variance inflation.

# Approach (a): Two sample t-test
```{r marginal_mpg_diff, cache = TRUE, message=FALSE, echo=FALSE}
mpg_delta_grp <- with(mtcars, mean(mpg[am == 'manual']) - mean(mpg[am == 'auto']))
```
**Figure 3** shows that in this data, `mpg` varies with `am`.  Mean mileage for manual is **`r round(mpg_delta_grp,1)` mpg** higher than automatic. We compute p-value and conf interval for the test of manual transmission greater.  
```{r t_test, comment=""}
t_test<-t.test(mpg~am,data=mtcars,alternative='less') # less: 2nd factor is t.test base
# note: code for processing and formatting of output suppressed
```

```{r t_output, echo = FALSE, comment=""}
cat(sep = "",  "p-value = ", 
    round(100*(t_test$p.value),2), "%", "     95% ", "conf.int = ", 
    round(-t_test$conf.int[2],2), " to ", -t_test$conf.int[1],"\n")
```
Given the p-value, we are highly confident manual is associated with higher fuel economy.

# Approach (b): OLS regression

Approach **(b)** is underspecified. Having identified `mpg` and `am` as of interest, the "correct" choice of model still depends on selection of the appropriate subset of 9 other variables. This should be a function of variable/model significance, but also *Motor Trend's* interests.  For significance testing, manual checking of p-values is inviable: at least $2^{9} = 512$ models with single predictors exist. Therefore, to fully specify and make the approach manageable, we make additional assumptions.

We assume *Motor Trend* values: **(A)** Parsimony/simplicity; **(B)** Models with granular, causal variables that may clarify engineering trade-offs; **(C)** Predictiveness: good generalizability outside the training sample.

## Model Search

Due to **(A)**, we consider no interactions.  From **(B)**, we exclude `qsec`, a summary metric.  Due to **(C)**, we rank models using the **AIC** metric, which estimates model predictiveness outside the training sample.  For OLS regression, the metric is $n\cdot Log(\sum_{i=1}^n(y_{i}- \hat{y}_{i})^2) + 2k$, where $k =$ # of paramaters, an overfitting penalty.  In fact, we use **AICc**, which corrects the penalty to be greater for small $n$. We use automated search to make evaluation of all $2^9$ models feasible. Models are ranked from smallest to largest AICc.  Only non-zero coefficients are shown.

```{r model_search, warning = FALSE, message=FALSE, comment="", results='hide'}
if (!"MuMIn" %in% row.names(installed.packages())) {install.packages("MuMIn")}
library(MuMIn); mtcars$qsec <- NULL; mtcars$gear <- as.factor(mtcars$gear)
globalmodel <- lm(mpg ~ ., data = mtcars, na.action = na.fail)
bestmodels <- dredge(globalmodel, subset = ~ am) # only considers models with `am`
bestmodels[1:5,]
```
```{r process_model_matrix, echo = FALSE, comment=""}
bmdf <- as.data.frame(bestmodels[1:5, ])
bmdf$disp <- NULL
bmdf$drat <- NULL
bmdf$gear <- NULL
bmdf[,c(1:4,6:11)] <- round(bmdf[,c(1:4,6:11)],1)
bmdf$weight <- round(bmdf$weight,2)
bmdf$hp <- round(bmdf$hp,2)
names(bmdf)[1] <- "(Int)"
bmdf <- format(bmdf)
bmdf[which(bmdf == "   NA", arr.ind = TRUE)] <- "     "
bmdf[which(bmdf == "  NA", arr.ind = TRUE)] <- "    "
bmdf[which(bmdf == " NA", arr.ind = TRUE)] <- "   "
bmdf
```

## Inference

We investigate values of the `am` coefficient for the top models. Note the first 3 all round to 2, suggesting this is a good rough estimate of the adjusted transmission effect. Although our top model is only one AICc point lower than the next best model (model averaging is suggested via the weights, for differences less than 2), we focus attention on it, in the spirit of Assumption **(A)**.
```{r coeftable_best, echo = FALSE, comment=""}
cotbls <- coefTable(bestmodels)
round(cotbls[["322"]][,1:2], 2)
```
The table contains no p-values, as after a search of $2^9$ models, these would be inflated (we expect 'good' p-values often, by chance alone).  However, standard errors are provided.  These indicate `hp` and `wt` are relatively significant, whereas significance of the the `am` coefficient, `r round(cotbls[['322']][2,1],2)`, is low. The Estimate divided by the Std. Error, typically used as the t-statistic, is only `r round(cotbls[['322']][2,1]/cotbls[['322']][2,2],1)`. Two is typically the significance threshold.  However, the $R^2$ of the top model is `r round(100*(bestsummary <- summary(lm(mpg ~ am + hp + wt, mtcars)))$r.squared, 2)`%: it explains a high degree of sample variance with only 3 covariates.

## Model Diagnostics

# Figures

```{r plot_integer_vars, fig.cap="Plot of continuous vs. factor variables in mtcars data"}
data(mtcars)
intplotsdf <- data.frame(mpg=mtcars$mpg, hp=mtcars$hp, cyl=mtcars$cyl, carb=mtcars$carb,
              gear=mtcars$gear, qsec=mtcars$qsec)
if (!"tidyr" %in% rownames(installed.packages())) {install.packages("tidyr")}
library(tidyr)
intplotsdf <- gather(data = intplotsdf, key = x_variable, 
                     value = x_value, -mpg, -hp, -qsec)
intplotsdf <- gather(data = intplotsdf, key = y_variable, 
                     value = y_value, -x_variable, -x_value)
if (!"ggplot2" %in% rownames(installed.packages())) {install.packages("ggplot2")}
library(ggplot2)
g_integer_vars <- ggplot(intplotsdf, aes(x=x_value,y=y_value)) + 
                         facet_grid(y_variable ~ x_variable, scales = "free") +
                  geom_point() + geom_smooth(method = "lm") +
labs(title = "'gear' behaves as a factor, 'carb' and 'cyl' can be treated as continous")
print(g_integer_vars)
```

```{r variable_definition, echo = FALSE}
mtcars$vs <- factor(x=as.character(mtcars$vs),levels=c("0","1"),labels=c("v","s"))
mtcars$am <- factor(x=as.character(mtcars$am),levels=c("0","1"),labels=c("auto","manual"))
mtcars$gear <- as.factor(mtcars$gear)
```

```{r pairs_plot, cache = TRUE, message = FALSE, fig.cap="Pairs Plot of Motor Trend Cars Database"}
if (!"GGally" %in% rownames(installed.packages())) {install.packages("GGally")}
library(GGally)
g_pairs <- ggpairs(mtcars, lower = list(continuous = wrap(ggally_smooth, color = "blue")),
           diag = list(continuous = "barDiag"), upper = list(continuous = wrap(ggally_cor,
           size = 3, color = "blue")), axisLabels = 'none')
print(g_pairs)
```

```{r violin_plot, fig.cap="Violin plot of MPG vs. Transmission type", message = FALSE}
g_violin <- ggplot(mtcars, aes(x = am, y = mpg)) + geom_violin() + 
        geom_dotplot(binaxis='y', stackdir='center', dotsize=1) +
        stat_summary(fun.y=mean, geom="point", shape=23, size=4, aes(fill = am)) +
        scale_fill_discrete(name="Mean MPG")+
        labs(title = "Average MPG for manual transmissions is significantly higher")
print(g_violin)
```
